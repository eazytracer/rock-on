---
created: 2025-11-21T23:44
feature: CI/CD Testing Pipeline
prompt: 'Research current testing infrastructure and propose comprehensive CI/CD pipeline'
status: research-complete
---

# CI/CD Testing Pipeline - Research Analysis

## Executive Summary

The rock-on project has a comprehensive test suite (555 tests across 63 files) but lacks CI/CD automation and pre-commit validation. This creates risk of broken code being merged and slows developer feedback loops.

**Current State:**

- ❌ No pre-commit hooks
- ❌ No GitHub Actions CI/CD
- ❌ Manual test orchestration required
- ⚠️ 64 failing tests (journey tests requiring Supabase setup)
- ⚠️ Test environment setup is manual and error-prone

**Proposed Solution:**

- ✅ Fast pre-commit validation (< 30s)
- ✅ Comprehensive GitHub Actions pipeline
- ✅ Automated Supabase orchestration in CI
- ✅ Parallel test execution (5-7 min total)
- ✅ Rich test reporting and debugging artifacts

## Current Test Infrastructure

### Test Counts by Type

```
Unit Tests:         33 files, 491 passing
Integration Tests:   1 file
Journey Tests:       4 files (require Supabase, 64 failing)
Contract Tests:      3 files (require Supabase)
E2E Tests:          11 files (Playwright)
Database Tests:     11 files (pgTAP)
---
Total:              555 tests across 63 test files
```

### Test Frameworks

- **Vitest 2.1.8:** Unit, integration, journey, contract tests
- **Playwright 1.49.0:** E2E browser tests
- **pgTAP:** Database schema validation

### Current Test Scripts

```json
{
  "test": "vitest run",
  "test:watch": "vitest",
  "test:coverage": "vitest run --coverage",
  "test:db": "supabase test db",
  "test:e2e": "playwright test",
  "test:e2e:ui": "playwright test --ui",
  "test:e2e:debug": "playwright test --debug",
  "test:e2e:report": "playwright show-report",
  "test:all": "npm run test && npm run test:db && npm run test:e2e",
  "start:test": "./scripts/start-test-env.sh && npm test"
}
```

## Identified Gaps & Pain Points

### Critical Issues

**1. No Pre-Commit Validation**

- ❌ No git hooks configured
- ❌ No husky setup
- ❌ No lint-staged for targeted testing
- **Impact:** Broken code can be committed easily

**2. No CI/CD Pipeline**

- ❌ No `.github/workflows/` directory exists
- ❌ No automated testing on PRs
- ❌ No automated testing on main branch
- **Impact:** No safety net before deployment

**3. Test Environment Orchestration**

- ⚠️ Manual Supabase startup required
- ⚠️ Manual environment variable management
- ⚠️ No automated cleanup between test runs
- **Impact:** Flaky tests, inconsistent results

**4. Test Execution Strategy**

- ⚠️ `npm test` runs all Vitest tests together (unit + integration + journey + contract)
- ⚠️ No separation of fast vs slow tests
- ⚠️ Journey/contract tests fail if Supabase not running
- **Impact:** Slow feedback loop, confusing failures

**5. Test State Management**

- ⚠️ Database tests have seed data contamination issues
- ⚠️ E2E tests don't reset database between runs
- ⚠️ No database snapshot/restore mechanism
- **Impact:** Test interdependencies, false failures

## Proposed Architecture

### Pre-Commit Flow (< 30s)

```
Developer Commits
    ↓
Git Hook (husky)
    ↓
Lint Staged Files → Fast Unit Tests → Type Check
    ↓                  ↓                 ↓
  ✅ Fixed          ✅ Passed         ✅ No errors
    ↓
Commit Allowed
```

### CI Pipeline Flow (5-7 min)

```
PR Opened/Updated
    ↓
GitHub Actions
    ↓
┌─────────────┬──────────────┬──────────────┬──────────────┐
│  Validate   │  Unit Tests  │ Integration  │  E2E Tests   │
│  (1 min)    │  (30s)       │  (1-2 min)   │  (2 min)     │
│             │              │              │              │
│ • Lint      │ • 33 files   │ • Supabase   │ • Supabase   │
│ • Format    │ • Coverage   │ • Journey    │ • 4 shards   │
│ • Types     │ • Parallel   │ • Contract   │ • Parallel   │
│             │              │ • Database   │ • Artifacts  │
└─────────────┴──────────────┴──────────────┴──────────────┘
    ↓             ↓              ↓              ↓
  ✅ Pass      ✅ Pass        ✅ Pass        ✅ Pass
    ↓
All Checks Passed → Merge Allowed
```

## Key Features

### 1. Pre-Commit Validation

**Tools:** husky + lint-staged
**Duration:** < 30 seconds
**Tests Run:**

- Lint and format staged files
- TypeScript type check
- Fast unit tests (25 files, no Supabase)

**Benefits:**

- Catches 80%+ of issues before CI
- Fast feedback loop
- Prevents broken commits

### 2. GitHub Actions Pipeline

**5 Parallel Stages:**

1. **Validate** (1 min, parallel)
   - ESLint, Prettier, TypeScript

2. **Unit Tests** (30s, parallel)
   - All 33 unit test files
   - 4 worker threads
   - Coverage reporting

3. **Integration Tests** (1-2 min, sequential)
   - Supabase startup + reset
   - Journey tests (4 files)
   - Contract tests (3 files)
   - Database tests (11 pgTAP files)

4. **E2E Tests** (2 min, parallel)
   - Supabase startup
   - Dev server startup
   - Playwright (11 files)
   - 4 test shards
   - Screenshots/videos on failure

5. **Report** (on completion)
   - Merge coverage reports
   - Generate GitHub Actions summary
   - Comment on PR with results

**Total Duration:** 5-7 minutes (with parallelization)

### 3. Supabase in CI

**Approach:** Supabase CLI with Docker

**Setup:**

```bash
npx supabase start         # Start local Supabase
npx supabase db reset      # Apply baseline migration
# Tests run
npx supabase stop          # Cleanup
```

**Why This Approach:**

- ✅ Same as local development
- ✅ Supports all Supabase features (Auth, Realtime)
- ✅ Isolated per CI run
- ⚠️ Adds 30-60s startup time

### 4. Test Parallelization

**Unit Tests:**

- 4 worker threads (Vitest pool)
- ~30s total duration

**E2E Tests:**

- 4 shards across matrix strategy
- Each shard runs ~25% of tests
- ~2 min total duration

**Integration Tests:**

- Sequential (share Supabase instance)
- ~1-2 min total duration

### 5. Rich Reporting

**GitHub Actions Native:**

- Job summaries with test results
- Annotations on failed tests
- Status checks on PRs

**Artifacts:**

- Playwright screenshots/videos
- Coverage reports
- Test logs

**Coverage Integration:**

- Codecov integration (optional)
- PR comments with coverage diff
- Fail on coverage decrease

## Technical Decisions

### Decision Matrix

| Decision         | Options                                      | Chosen                   | Rationale                 |
| ---------------- | -------------------------------------------- | ------------------------ | ------------------------- |
| Supabase in CI   | CLI/Docker, PostgreSQL service, Remote       | CLI/Docker               | Feature parity with local |
| Pre-commit scope | All tests, Fast tests, Affected tests        | Fast tests only          | Speed vs completeness     |
| Parallelization  | Sequential, Per-stage, Cross-stage           | Per-stage + E2E sharding | Balance complexity/speed  |
| Test isolation   | Shared DB, Per-file DB, Transaction rollback | Transaction + resets     | Fast and reliable         |
| Coverage         | No requirement, Strict, Progressive          | Progressive thresholds   | Prevent regression        |

## Implementation Estimate

### Phase 1: Pre-Commit Validation (2-4 hours)

- Install husky and lint-staged
- Create pre-commit hook script
- Update package.json scripts
- Test locally

**Risk:** Low

### Phase 2: Core Pipeline (8-12 hours)

- Create `.github/workflows/ci.yml`
- Setup Supabase in CI
- Implement validate stage
- Implement unit test stage
- Implement integration test stage
- Implement E2E test stage

**Risk:** Medium (Supabase in CI is new)

### Phase 3: Advanced Features (12-16 hours)

- E2E test sharding (4 shards)
- Coverage reporting (Codecov)
- Test artifact collection
- PR comments with summaries

**Risk:** Medium

### Phase 4: Optimization & Polish (8-12 hours)

- Vitest parallelization tuning
- GitHub Actions caching
- Notification setup (optional)
- Documentation updates

**Risk:** Low

**Total Effort:** 30-44 hours (4-6 days for one person)

## Success Metrics

**Pre-Commit:**

- ✅ Execution time < 30 seconds
- ✅ Catches 80%+ of lint/type/unit test issues
- ✅ Developer adoption rate > 90%

**CI Pipeline:**

- ✅ Total execution time < 10 minutes
- ✅ Flaky test rate < 5%
- ✅ All test types pass consistently
- ✅ Clear failure reporting with artifacts

**Project Health:**

- ✅ Zero broken commits merged to main
- ✅ Test coverage visible and tracked
- ✅ Automated regression prevention

## Risks & Mitigation

### High Risk

**1. CI Supabase Setup Complexity**

- **Issue:** Running Supabase in GitHub Actions is complex
- **Impact:** CI pipeline may be fragile or slow
- **Mitigation:** Use Supabase CLI with Docker containers, implement health checks

**2. Test Environment Contamination**

- **Issue:** Tests sharing database state causing failures
- **Impact:** Flaky tests, hard to debug failures
- **Mitigation:** Database snapshots, transaction rollbacks, isolated test databases

**3. E2E Test Reliability in CI**

- **Issue:** Headless browser tests can be flaky
- **Impact:** False failures blocking merges
- **Mitigation:** Retry logic, proper waits, screenshot/video artifacts on failure

### Medium Risk

**4. Test Execution Time**

- **Issue:** Full test suite may take 5-10 minutes
- **Impact:** Slow feedback loop
- **Mitigation:** Parallel execution, test sharding, smart test selection

**5. Environment Variable Security**

- **Issue:** Secrets in CI need proper management
- **Impact:** Leaked credentials or broken tests
- **Mitigation:** GitHub Secrets, encrypted variables, validation

## Open Questions

1. **Coverage Requirements:**
   - What should initial coverage thresholds be?
   - Should we fail CI on coverage decrease?
     **_Answer_**
   - 60% as suggested is fine for starting, we do not need to fail on any decrease, just dropping below threshold

2. **Notification Strategy:**
   - Who should be notified on test failures?
   - Should we integrate with Slack/Discord?
     **_Answer_**
   - This is a solo dev project, Github already emails me on failures, that's good enough for now

3. **Performance Budget:**
   - What's acceptable CI execution time?
   - Should we invest in faster runners?
     **_Answer_**
   - My only concern for this is cost. I am using Github for free right now, I may move to Gitea on my homelab to do more parallel processing and remove cost concerns, but for now just do what can be done in the free tier

4. **Test Data Management:**
   - Should we use test fixtures or generate data?
   - How to handle test data cleanup?
     **_Answer_**
   - I'm open to suggestions here, what are some common procedures and pros/cons? I think our app is simple enough we can use our existing .sql seed data for now, but maybe that's not ideal long-term?

5. **Branch Protection:**
   - Should we require all status checks to pass?
   - Should we require manual approval for certain changes?
     **_Answer_**
   - Yes, all status should pass before allowing merge. We are going to eventually move to having a stable test build and a main branch build, we will want passing tests for both. Manual approval should be done at the pull request level.

## Recommended Next Steps

1. **User Review:**
   - Review this research document
   - Answer open questions above
   - Confirm acceptable trade-offs

2. **Proceed to Planning:**
   - Create detailed implementation plan
   - Break down into tasks
   - Estimate each task
   - Identify dependencies

3. **Implementation:**
   - Start with Phase 1 (pre-commit)
   - Progressive rollout
   - Monitor and adjust

## References

- `tests/README.md` - Test overview
- `.claude/setup/TESTING-ENVIRONMENT-SETUP.md` - Test setup guide
- `ENVIRONMENTS.md` - Environment management
- `package.json` - Current test scripts
- `playwright.config.ts` - E2E configuration
- `vite.config.ts` - Vitest configuration
- `.claude/artifacts/2025-11-20T22:39_v1-roadmap.md` - Project roadmap
